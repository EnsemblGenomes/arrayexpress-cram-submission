# arrayexpress-cram-submission
[![Build Status](https://travis-ci.org/EnsemblGenomes/arrayexpress-cram-submission.svg?branch=master)](https://travis-ci.org/EnsemblGenomes/arrayexpress-cram-submission)
[![Coverage Status](https://coveralls.io/repos/github/EnsemblGenomes/arrayexpress-cram-submission/badge.svg?branch=master)](https://coveralls.io/github/EnsemblGenomes/arrayexpress-cram-submission?branch=master)

A python 3 pipeline for submitting [CRAM](http://www.ebi.ac.uk/ena/software/cram-toolkit) files generated by
[ArrayExpress](https://www.ebi.ac.uk/arrayexpress/) to the  [European Nucleotide Archive](http://www.ebi.ac.uk/ena) (ENA).

## Installation
Get a copy of the project and install python dependencies with `pip install -r requirements.txt`.

Or build the docker image and skipt the next section.

## Setup
Start the [central scheduler](http://luigi.readthedocs.io/en/stable/central_scheduler.html)
```bash
luigid
```
and visit it on port 8082, e.g. <http://localhost:8082>. Then run a pipeline and follow the progress in your browser. 
The localhost needs to be the name of the local (or farm) server you are working on.

## Submitting all CRAM files for a species
#### Bash
```bash
export ena_user=webin-xxx
export ena_password=xxxxxxxx
luigi --module pipeline SubmitSpecies --species oryza_sativa 
```

#### Docker
```bash
docker run \
	-e "ena_user=webin-xxx" \
	-e "ena_password=xxxxxxxx" \
	<image> SubmitSpecies --species oryza_sativa
```
 This will
 1. make a request to [getRunsByOrganism](http://www.ebi.ac.uk/fg/rnaseq/api/json/70/getRunsByOrganism/oryza_sativa) on the ArrayExpress API to fetch a list of all Oryza sativa CRAM files which have been marked as 'Complete'
 2. upload each CRAM file to the European Nucleotide Archive (ENA) FTP server
 3. collect metadata required for the submission
 4. create 'submission' and 'analysis' XML documents required for [programmatic submission](http://www.ebi.ac.uk/ena/submit/programmatic-submission) to the ENA and submit them
 5. store the resulting submission and analysis accessions in an SQLite database

### Testing
Add `--test --limit 3` to the luigi command to sumit to the ENA test server (results are not publicly visible) and sumit only 3 CRAM files instead of all.

## Submitting CRAM files for all plant species
#### Bash
```bash
export ena_user=webin-xxx
export ena_password=xxxxxxxx
luigi --module pipeline SubmitAllSpecies
```

#### Docker
```bash
docker run \
	-e "ena_user=webin-xxx" \
	-e "ena_password=xxxxxxxx" \
	<image> SubmitAllSpecies
```

This will make a request to [getOrganisms](http://www.ebi.ac.uk/fg/rnaseq/api/json/70/getOrganisms/plants) on the ArrayExpress API to fetch a list of all plant species, and run SubmitSpecies (described above) for each.

## Scaling
Multiple workers can be run in parallel on the same host by adding the `--workers` parameter. E.g. `luigi --module pipeline SubmitAllSpecies --workers 8`. Since this pipeline is limited by the throughput of the ArrayExpress and ENA FTP servers, increasing the number of workers beyond this will not improve performance.

## Background
Every step from discovering CRAM files, over collecting metadata, to submitting to ENA is implemented as a
[luigi](https://github.com/spotify/luigi) [Task](http://luigi.readthedocs.io/en/stable/tasks.html).

This makes it easy to deal with failures that inevitably will happen when e.g. some of 30k+ long running tasks that have
dependencies between each other will fail. Instead of cleaning up after failed tasks, resetting state, or being forced to
 start again from scratch we can rely on luigi to check the completion of (atomic) tasks and resume safely.

Programmatic submission to the European Nucleotide Archive requires the creation of 'submission' and 'analysis' XML documents, following the [provided schemas](http://www.ebi.ac.uk/ena/submit/read-xml-format-1-5).
These documents are created with the help of [generateDS](http://www.davekuhlman.org/generateDS.html), which generates an API to match the schemas. The generated code is in `ena/schema`.

Should the schemas change, a new version of the API can be generated with
```bash
generateDS.py -o "SRA_analysis.py" -s "SRA_analysis_sub.py" SRA.analysis.xsd
generateDS.py -o "SRA_submission.py" -s "SRA_submission_sub.py" SRA.submission.xsd
```
