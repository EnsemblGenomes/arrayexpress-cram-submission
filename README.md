# arrayexpress-cram-submission
[![Build Status](https://travis-ci.org/EnsemblGenomes/arrayexpress-cram-submission.svg?branch=master)](https://travis-ci.org/EnsemblGenomes/arrayexpress-cram-submission)
[![Coverage Status](https://coveralls.io/repos/github/EnsemblGenomes/arrayexpress-cram-submission/badge.svg?branch=master)](https://coveralls.io/github/EnsemblGenomes/arrayexpress-cram-submission?branch=master)

A python 3 pipeline for submitting [CRAM](http://www.ebi.ac.uk/ena/software/cram-toolkit) files generated by
[ArrayExpress](https://www.ebi.ac.uk/arrayexpress/) to the  [European Nucleotide Archive](http://www.ebi.ac.uk/ena) (ENA).

## Installation
Get a copy of the project and install python dependencies with `pip install -r requirements.txt`

## Submitting all CRAM files for a species
```bash
export ena_user=webin-xxx
export ena_password=xxxxxxxx
luigi --module pipeline SubmitSpecies --species oryza_sativa --local-scheduler
```
 This will
 1. make a request to [getRunsByOrganism](http://www.ebi.ac.uk/fg/rnaseq/api/json/70/getRunsByOrganism/oryza_sativa) on the ArrayExpress API to fetch a list of all Oryza sativa CRAM files which have been marked as 'Complete'
 2. upload each CRAM file to the European Nucleotide Archive (ENA) FTP server
 3. collect metadata required for the submission
 4. create 'submission' and 'analysis' XML documents required for [programmatic submission](http://www.ebi.ac.uk/ena/submit/programmatic-submission) to the ENA and submit them
 5. store the resulting submission and analysis accessions in an SQLite database

## Submitting CRAM files for all plant species
```bash
export ena_user=webin-xxx
export ena_password=xxxxxxxx
luigi --module pipeline SubmitAllSpecies --local-scheduler
```
This will make a request to [getOrganisms](http://www.ebi.ac.uk/fg/rnaseq/api/json/70/getOrganisms/plants) on the ArrayExpress API to fetch a list of all plant species, and run SubmitSpecies (described above) for each.

## Scaling
Multiple workers can be run in parallel on the same host by adding the `--workers` parameter. E.g. `luigi --module pipeline SubmitAllSpecies --local-scheduler --workers 8`. Since this pipeline is limited by the throughput of the ArrayExpress and ENA FTP servers, increasing the number of workers beyond this will not improve performance.

## Background
Every step from discovering CRAM files, over collecting metadata, to submitting to ENA is implemented as a
[luigi](https://github.com/spotify/luigi) [Task](http://luigi.readthedocs.io/en/stable/tasks.html).

This makes it easy to deal with failures that inevitably will happen when e.g. some of 30k+ long running tasks that have
dependencies between each other will fail. Instead of cleaning up after failed tasks, resetting state, or being forced to
 start again from scratch we can rely on luigi to check the completion of (atomic) tasks and safely resume.
